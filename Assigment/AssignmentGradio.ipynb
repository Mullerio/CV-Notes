{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food Classification UI using Gradio \n",
    "\n",
    "I am using my own pretrained model for this, you can find it at: https://huggingface.co/Mullerjo/food-101-finetuned-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6004b595d7ed4dddaea86b4ee529d2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688dac4d931b4c73ae0982f52803be98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/344M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained('Mullerjo/food-101-finetuned-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6,\n",
       " 1: 79,\n",
       " 2: 81,\n",
       " 3: 53,\n",
       " 4: 10,\n",
       " 5: 20,\n",
       " 6: 77,\n",
       " 7: 48,\n",
       " 8: 86,\n",
       " 9: 84,\n",
       " 10: 76,\n",
       " 11: 34,\n",
       " 12: 51,\n",
       " 13: 21,\n",
       " 14: 64,\n",
       " 15: 0,\n",
       " 16: 43,\n",
       " 17: 44,\n",
       " 18: 73,\n",
       " 19: 57,\n",
       " 20: 14,\n",
       " 21: 5,\n",
       " 22: 46,\n",
       " 23: 55,\n",
       " 24: 93,\n",
       " 25: 98,\n",
       " 26: 38,\n",
       " 27: 11,\n",
       " 28: 99,\n",
       " 29: 72,\n",
       " 30: 22,\n",
       " 31: 59,\n",
       " 32: 70,\n",
       " 33: 16,\n",
       " 34: 2,\n",
       " 35: 58,\n",
       " 36: 83,\n",
       " 37: 96,\n",
       " 38: 39,\n",
       " 39: 49,\n",
       " 40: 45,\n",
       " 41: 88,\n",
       " 42: 9,\n",
       " 43: 26,\n",
       " 44: 94,\n",
       " 45: 4,\n",
       " 46: 65,\n",
       " 47: 32,\n",
       " 48: 27,\n",
       " 49: 36,\n",
       " 50: 87,\n",
       " 51: 69,\n",
       " 52: 85,\n",
       " 53: 25,\n",
       " 54: 40,\n",
       " 55: 19,\n",
       " 56: 35,\n",
       " 57: 56,\n",
       " 58: 42,\n",
       " 59: 60,\n",
       " 60: 68,\n",
       " 61: 100,\n",
       " 62: 41,\n",
       " 63: 92,\n",
       " 64: 24,\n",
       " 65: 3,\n",
       " 66: 89,\n",
       " 67: 75,\n",
       " 68: 17,\n",
       " 69: 97,\n",
       " 70: 61,\n",
       " 71: 33,\n",
       " 72: 80,\n",
       " 73: 30,\n",
       " 74: 8,\n",
       " 75: 74,\n",
       " 76: 66,\n",
       " 77: 31,\n",
       " 78: 18,\n",
       " 79: 67,\n",
       " 80: 37,\n",
       " 81: 13,\n",
       " 82: 63,\n",
       " 83: 28,\n",
       " 84: 47,\n",
       " 85: 52,\n",
       " 86: 54,\n",
       " 87: 1,\n",
       " 88: 82,\n",
       " 89: 91,\n",
       " 90: 95,\n",
       " 91: 7,\n",
       " 92: 29,\n",
       " 93: 78,\n",
       " 94: 15,\n",
       " 95: 23,\n",
       " 96: 12,\n",
       " 97: 62,\n",
       " 98: 50,\n",
       " 99: 71,\n",
       " 100: 90}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_class = {\n",
    "  \"apple_pie\": 0,\n",
    "  \"baby_back_ribs\": 1,\n",
    "  \"baklava\": 2,\n",
    "  \"beef_carpaccio\": 3,\n",
    "  \"beef_tartare\": 4,\n",
    "  \"beet_salad\": 5,\n",
    "  \"beignets\": 6,\n",
    "  \"bibimbap\": 7,\n",
    "  \"bread_pudding\": 8,\n",
    "  \"breakfast_burrito\": 9,\n",
    "  \"bruschetta\": 10,\n",
    "  \"caesar_salad\": 11,\n",
    "  \"cannoli\": 12,\n",
    "  \"caprese_salad\": 13,\n",
    "  \"carrot_cake\": 14,\n",
    "  \"ceviche\": 15,\n",
    "  \"cheesecake\": 16,\n",
    "  \"cheese_plate\": 17,\n",
    "  \"chicken_curry\": 18,\n",
    "  \"chicken_quesadilla\": 19,\n",
    "  \"chicken_wings\": 20,\n",
    "  \"chocolate_cake\": 21,\n",
    "  \"chocolate_mousse\": 22,\n",
    "  \"churros\": 23,\n",
    "  \"clam_chowder\": 24,\n",
    "  \"club_sandwich\": 25,\n",
    "  \"crab_cakes\": 26,\n",
    "  \"creme_brulee\": 27,\n",
    "  \"croque_madame\": 28,\n",
    "  \"cup_cakes\": 29,\n",
    "  \"deviled_eggs\": 30,\n",
    "  \"donuts\": 31,\n",
    "  \"dumplings\": 32,\n",
    "  \"edamame\": 33,\n",
    "  \"eggs_benedict\": 34,\n",
    "  \"escargots\": 35,\n",
    "  \"falafel\": 36,\n",
    "  \"filet_mignon\": 37,\n",
    "  \"fish_and_chips\": 38,\n",
    "  \"foie_gras\": 39,\n",
    "  \"french_fries\": 40,\n",
    "  \"french_onion_soup\": 41,\n",
    "  \"french_toast\": 42,\n",
    "  \"fried_calamari\": 43,\n",
    "  \"fried_rice\": 44,\n",
    "  \"frozen_yogurt\": 45,\n",
    "  \"garlic_bread\": 46,\n",
    "  \"gnocchi\": 47,\n",
    "  \"greek_salad\": 48,\n",
    "  \"grilled_cheese_sandwich\": 49,\n",
    "  \"grilled_salmon\": 50,\n",
    "  \"guacamole\": 51,\n",
    "  \"gyoza\": 52,\n",
    "  \"hamburger\": 53,\n",
    "  \"hot_and_sour_soup\": 54,\n",
    "  \"hot_dog\": 55,\n",
    "  \"huevos_rancheros\": 56,\n",
    "  \"hummus\": 57,\n",
    "  \"ice_cream\": 58,\n",
    "  \"lasagna\": 59,\n",
    "  \"lobster_bisque\": 60,\n",
    "  \"lobster_roll_sandwich\": 61,\n",
    "  \"macaroni_and_cheese\": 62,\n",
    "  \"macarons\": 63,\n",
    "  \"miso_soup\": 64,\n",
    "  \"mussels\": 65,\n",
    "  \"nachos\": 66,\n",
    "  \"omelette\": 67,\n",
    "  \"onion_rings\": 68,\n",
    "  \"oysters\": 69,\n",
    "  \"pad_thai\": 70,\n",
    "  \"paella\": 71,\n",
    "  \"pancakes\": 72,\n",
    "  \"panna_cotta\": 73,\n",
    "  \"peking_duck\": 74,\n",
    "  \"pho\": 75,\n",
    "  \"pizza\": 76,\n",
    "  \"pork_chop\": 77,\n",
    "  \"poutine\": 78,\n",
    "  \"prime_rib\": 79,\n",
    "  \"pulled_pork_sandwich\": 80,\n",
    "  \"ramen\": 81,\n",
    "  \"ravioli\": 82,\n",
    "  \"red_velvet_cake\": 83,\n",
    "  \"risotto\": 84,\n",
    "  \"samosa\": 85,\n",
    "  \"sashimi\": 86,\n",
    "  \"scallops\": 87,\n",
    "  \"seaweed_salad\": 88,\n",
    "  \"shrimp_and_grits\": 89,\n",
    "  \"spaghetti_bolognese\": 90,\n",
    "  \"spaghetti_carbonara\": 91,\n",
    "  \"spring_rolls\": 92,\n",
    "  \"steak\": 93,\n",
    "  \"strawberry_shortcake\": 94,\n",
    "  \"sushi\": 95,\n",
    "  \"tacos\": 96,\n",
    "  \"takoyaki\": 97,\n",
    "  \"tiramisu\": 98,\n",
    "  \"tuna_tartare\": 99,\n",
    "  \"waffles\": 100\n",
    "}\n",
    "\n",
    "class_to_label = {v: k for k, v in label_to_class.items()}\n",
    "class_labels = model.config.id2label\n",
    "class_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "def classify_image(img):\n",
    "    img = Image.fromarray(img)\n",
    "    img = preprocess(img)\n",
    "    img = img.unsqueeze(0)  # Add batch dimension\n",
    "    img = img.to(device)     # Move to device\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "    logits = outputs.logits.squeeze().tolist()  # Squeeze and convert to list\n",
    "    # Get indices of top 3 logits\n",
    "    top3_indices = heapq.nlargest(3, range(len(logits)), key=logits.__getitem__)\n",
    "    # Get corresponding class names\n",
    "    top3_classes = [class_to_label[class_labels[idx]] for idx in top3_indices]\n",
    "    words = top3_classes\n",
    "    outp = f\"The most likely food is {words[0]}! Ff that seems unlikely it could also be {words[1]} or {words[2]} :)\"\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=classify_image,\n",
    "    inputs=gr.Image(type=\"numpy\"),\n",
    "    outputs=gr.Textbox(label=\"Output\"),    \n",
    "    title=\"Food Image Classifier\",\n",
    "    description=\"Upload an image of food and get the predicted category.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has the following classes: {0: 6, 1: 79, 2: 81, 3: 53, 4: 10, 5: 20, 6: 77, 7: 48, 8: 86, 9: 84, 10: 76, 11: 34, 12: 51, 13: 21, 14: 64, 15: 0, 16: 43, 17: 44, 18: 73, 19: 57, 20: 14, 21: 5, 22: 46, 23: 55, 24: 93, 25: 98, 26: 38, 27: 11, 28: 99, 29: 72, 30: 22, 31: 59, 32: 70, 33: 16, 34: 2, 35: 58, 36: 83, 37: 96, 38: 39, 39: 49, 40: 45, 41: 88, 42: 9, 43: 26, 44: 94, 45: 4, 46: 65, 47: 32, 48: 27, 49: 36, 50: 87, 51: 69, 52: 85, 53: 25, 54: 40, 55: 19, 56: 35, 57: 56, 58: 42, 59: 60, 60: 68, 61: 100, 62: 41, 63: 92, 64: 24, 65: 3, 66: 89, 67: 75, 68: 17, 69: 97, 70: 61, 71: 33, 72: 80, 73: 30, 74: 8, 75: 74, 76: 66, 77: 31, 78: 18, 79: 67, 80: 37, 81: 13, 82: 63, 83: 28, 84: 47, 85: 52, 86: 54, 87: 1, 88: 82, 89: 91, 90: 95, 91: 7, 92: 29, 93: 78, 94: 15, 95: 23, 96: 12, 97: 62, 98: 50, 99: 71, 100: 90}\n"
     ]
    }
   ],
   "source": [
    "if hasattr(model.config, 'id2label'):\n",
    "    class_labels = model.config.id2label\n",
    "    print(f\"The model has the following classes: {class_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
